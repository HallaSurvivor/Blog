---
layout: post
title: How Holomorphic Functions are Just Like Polynomials
tags:
  - 
---

I took a complex exam ~~last week~~ a while ago, and while I was studying I
realized that a lot of the theorems were saying that holomorphic functions
behave like polynomials. This makes sense, since a holomorphic function,
which locally has a power series, looks like a polynomial of infinite degree,
but there's actually quite a bit to say here! With that in mind, I decided to 
write up some quick thoughts about this, in line with my post from a while ago
talking about banach space theorems generalizing finite dimensional linear
algebra (see [here][1]). Now, on with the show!

---

I mentioned this in the introduction, but it's worth stating the obvious. 
A holomorphic function locally looks like a power series 

$$a_0 + a_1 (z - \xi) + a_2 (z - \xi)^2 + \ldots$$

that is, a "polynomial of infinite degree". With this in mind, there's lots
of well known formulas that work for polynomials that continue to the 
holmorphic setting. For instance, we can differentiate and integrate
term by term (provided we stay inside the radius of convergence), and if we 
have two series, we can add and multiply them exactly as we would polynomials
(term by term for addition, and via the [cauchy product][2] formula for products)
provided we stay inside the radius of convergence for _both_ series.

In fact, there are deeper ways in which holomorphic functions act like polynomials.
For a start, polynomials over $\mathbb{C}$ always factor as some constant times
a product of roots. That is, we always have

$$
p(z) = c \prod_{\rho} (z - \rho)
$$

(where the roots $\rho$ are counted with multiplicity, of course).

This says that, up to [units][3], polynomials are in bijection with 
finite (multi)sets of points in the complex plane. 

The situation for holomorphic functions is more delicate, but only
slightly. The <span class=defn>Weierstrass Factorization Theorem</span>
tells us that every holomorphic function factors as 

$$
f(z) = e^g z^m \prod_{\rho} E_{n_\rho} \left ( \frac{z}{\rho} \right )
$$

Here $e^g$ is nowhere zero, thus is a unit in the ring of holomorphic functions,
and the function $E_{n_\rho} \left ( \frac{z}{\rho} \right )$ is zero only at a 
nonzero root $\rho$, so is analogous to the factor $(z - \rho)$, and we also
have $m$ factors of $z$ which correspond to the order of vanishing of $f$ at $0$.

These functions $E_k \left ( \frac{z}{\rho} \right )$, which differ from
$(z - \rho)$ only by units, are cleverly chosen to force the infinite product
to converge, which is an issue we don't have in the case of polynomials[^3].

Conversely, we would like to know that to any family of points in the plane,
we can associate a holomorphic function with precisely those points as roots.
This is possible, but the key insight is a hidden assumption in the case of 
polynomials: a finite set of points ia always _discrete_! If we want to allow
for infinitely many zeroes, we have to explicitly demand discreteness of the
set of zeroes[^1].

But this is the only obstruction! Say $(a_n)$ is a discrete set of points 
in the plane, and $(r_n)$ is a sequence of natural numbers.
Then there exists a holomorphic function, unique up to units,
which vanishes to order $r_n$ at $a_n$, and nowhere else[^2].

<div class=boxed markdown=1>
  As a quick exercise, this data is often repackaged by saying that 
  $(a_n)$ is a _sequence_ of points in the plane with $|a_n| \to \infty$.

  Show that this condition is equivalent to ours.
</div>

Next up is the argument principle, which lets us count the number of zeroes
$f$ has in some region.

For polynomials, the key insight is that the [logarithmic derivative][5] 
turns products into sums. That is,

$$
\frac{(uv)'}{uv} = \frac{u'}{u} + \frac{v'}{v}
$$

So if we factor our polynomial as $c \prod (z - \rho)$, we can use this 
formula to compute the logarithmic derivative:

$$
\frac{p'}{p} = 
\frac{c \left ( \prod (z - \rho) \right )'}{c \prod (z-\rho)} =
\sum \frac{(z - \rho)'}{z-\rho} =
\sum \frac{1}{z-\rho}
$$

Of course, it's easy to compute the integral of this sum along a (simple) closed
contour! We pick up a $2\pi i$ is $\rho$ is inside the contour, and a $0$ otherwise.

So integrating both sides, we see that

$$
\oint_\gamma \frac{p'}{p}\ dz = 2 \pi i \left ( \# \text{roots inside $\gamma$} \right )
$$

The remarkable thing is that this formula goes through entirely unchanged when
we pass to holomorphic functions[^4]! 

---

Lastly, let's give an important property that _does_ change when we move from
the polynomial setting to the holomorphic one: growth rates!

<div class=boxed markdown=1>
As a preemptive exercise, you should show that any holomorphic function $f$
with $|f| = O(|z|^n)$ for some $n$ must itself be a polynomial. 

You'll want to use [Liouville's theorem][6]!
</div>

So a holomorphic function which grows polynomially quickly is itself a polynomial.
Taking contrapositives, we see that any nonpolynomial holomorphic function must
grow faster than any polynomial! This gives rise to an obvious question: 

How quickly _can_ holomorphic functions grow?

Well, in the last section we said that for any discrete sequence $(a_n)$, and for
any values $A_n$ we like, we can find a holomorphic function $f$ so that
$f(a_n) = A_n$.

For simplicity, let's take $a_n = n$ to be integers. Now let's take 
$A_n \triangleq n!$. Or better yet, $A_n = (n!)!$. What the hell, let's let
$A_n \triangleq \mathtt{Ack}(n,n)$ the diagonal of the [ackermann function][7]!

The theorem from the last section says that there's a holomorphic function which
grows at least as quickly as $\mathtt{Ack}(n,n)$, but it's easy to see that
we can make functions which grow as quickly as we like by modifying this argument[^5]!

This should be some mild warning that, despite many other similarities, there
is still a marked difference between the behavior of holomorphic (even entire!) 
functions and polynomials.

---

Finally a truly quick one! Can you believe a post this short has been in my 
drafts for almost a month now? I still have plans for some more exciting posts
coming up, but I've been really overwhelmed with work lately. 

One fun, thing is that I'm running a reading course for some undergraduates on 
[locale theory][10], and I might try to keep a running series where I summarize
what we do on any given week. 

So far we've mainly been reviewing the definitions of categories, which I don't
think I need to go into here, but once we start doing more interesting things
I'd like to post my thoughts here as we go. No promises, though!

If nothing else, I have another post which is _almost_ done, and I should 
hopefully post it soon! I'll see you all there ^_^

---

[^1]:
    After all, by uniqueness of analytic continuation, if the zeroes of a 
    holomorphic function contain a limit point, then that function _must_ be
    identically zero!

    So if we want to be able to say the zeroes are on our specified points
    and _nowhere else_, then the desired set of zeroes cannot contain a limit 
    point.

[^2]:
    Remarkably _much_ more is true! 

    We can specify nonzero values at some discrete family of points, 
    and we can even specify the first finitely many derivatives at those
    points!

    Formally, if $a_n$ is some discrete set of points, and $k$ is some fixed integer,
    then for any values $A_n^0, A_n^1, A_n^2, \ldots, A_n^k$,
    there's a holomorpic function (unique up to units) so that for every 
    $0 \leq j \leq k$, and for every $n$, we have

    $$
    \left . \frac{d^j f}{dz^j} \right |_{a_n} = A_n^j
    $$

    This is _incredible_, since it seems to fly in the face of the rigidity
    of holomorphic functions. It's wild to me that there should be _such_ a 
    wealth of holomorphic functions which we can create to our specifications.
    I (unsurprisingly) first heard about this result on [mse][4], and I don't
    actually have a reference besides that... If someone happens to know one,
    I would love to hear about it!

[^3]:
    More details can be found in Conway's _Functions of One Complex Variable_
    section $VII.5$, but basically 

    $$
    E_k(z) \triangleq 
    (1 - z) 
    \exp \left ( z + \frac{z^2}{2} + \frac{z^3}{3} + \ldots + \frac{z^k}{k} \right )
    $$

    so in particular, $E_k \left ( \frac{z}{\rho} \right )$ is zero precisely when
    $z = \rho$. 

    Notice we could just as easily factor a polynomial $p$ as

    $$p(z) = c z^m \prod \left ( 1 - \frac{z}{\rho} \right )$$

    where the $\rho$ are the nonzero roots of $p$, and this differs from
    the usual factorization only by a unit. 

    Writing $p$ in this way makes the analogy with the weierstrass factorization
    theorem much more obvious.

[^4]:
    This is basically because the region bounded by $\gamma$ is compact. Thus
    it can contain only finitely many roots (do you see why?) so we can write
    $f$ as a _finite_ product of roots inside $\gamma$ (just like our polynomial!)
    times some function $g$ which is nonzero inside $\gamma$. Then we apply our
    formula for the logarithmic derivative exactly as we did for polynomials,
    but we'll get some final term of the form $\frac{g'}{g}$, whose integral
    is also $0$.

[^5]:
    This doesn't really fit in with the rest of the post, but I want to mention it,
    so... footnote :P

    It turns out that we can _lower_ bound the growth rate of a holomorphic function
    by understanding the density of its zeroes. This amounts to 
    [jensen's formula][8], which you can read about on Terry Tao's blog
    [here][9].

    As a cute problem of this format, here's a homework question from UCR's 
    complex analysis class:

    <div class=boxed markdown=1>
    Let $t > 0$ be fixed, and let 

    $$
    f(z) \triangleq \prod_{n=1}^\infty 
    \left (
      1 - \exp(-2\pi n t) \exp (2 \pi i z)
    \right )
    $$

    In particular, $f$ has zeroes at exactly $m - int$ for $m,n \in \mathbb{Z}$.

    Show that 

    $$
    \max_{|z| < R} |f(z)| = 
    \Omega \left ( \exp \left ( \frac{\pi R^2}{4t} \right )\right )
    $$
    </div>

    In proving this (using jensen's formula), you'll want to estimate the 
    number of zeroes in a circle of radius $R$, which you can (and should)
    do geometrically.


[1]: /2021/09/09/banach-spaces.html
[2]: https://en.wikipedia.org/wiki/Cauchy_product
[3]: https://en.wikipedia.org/wiki/Unit_(ring_theory)
[4]: https://math.stackexchange.com/questions/1627388/is-there-an-upper-bound-on-the-growth-rate-of-analytic-functions
[5]: https://en.wikipedia.org/wiki/Logarithmic_derivative
[6]: https://en.wikipedia.org/wiki/Liouville%27s_theorem_(complex_analysis)
[7]: https://en.wikipedia.org/wiki/Ackermann_function
[8]: https://en.wikipedia.org/wiki/Jensen%27s_formula
[9]: https://terrytao.wordpress.com/2020/12/23/246b-notes-1-zeroes-poles-and-factorisation-of-meromorphic-functions/
[10]: https://en.wikipedia.org/wiki/Pointless_topology
